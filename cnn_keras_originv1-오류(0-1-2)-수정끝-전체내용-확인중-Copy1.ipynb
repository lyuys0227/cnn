{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential  \n",
    "from keras.layers import Dense, Dropout, Activation, Flatten  \n",
    "from keras.layers import Convolution2D, MaxPooling2D  \n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from scipy import misc\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import math\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델과 r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "width = 1\n",
    "height = 1\n",
    "\n",
    "# R2\n",
    "def r_squared(y_true, y_hat):\n",
    "    ssr = 0\n",
    "    sst = 0\n",
    "    e = np.subtract(y_true, y_hat)\n",
    "    y_mean = np.mean(y_true)\n",
    "    for item in e:\n",
    "        ssr += item**2\n",
    "    for item in y_true:\n",
    "        sst += (item - y_mean)**2\n",
    "    r2 = 1 - ssr / sst\n",
    "    return r2\n",
    "\n",
    "#compile()함수 이용해서 모델 학습과정 설정하기\n",
    "def compile_model(model):\n",
    "    lrate = 0.01\n",
    "    sgd = SGD(lr=lrate, momentum=0.9, decay=1e-6, nesterov=True)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=sgd)\n",
    "    return model\n",
    "\n",
    "#model \n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Convolution2D(32, 3, 3,\n",
    "                            border_mode='valid', \n",
    "                            input_shape=(100, 100, 3)))  \n",
    "    model.add(Activation('relu'))  \n",
    "    model.add(Convolution2D(32, 3, 3))  \n",
    "    model.add(Activation('relu'))  \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))  \n",
    "    model.add(Dropout(0.25))  \n",
    "      \n",
    "    model.add(Convolution2D(64, 3, 3, \n",
    "                            border_mode='valid'))  \n",
    "    model.add(Activation('relu'))  \n",
    "    model.add(Convolution2D(64, 3, 3))  \n",
    "    model.add(Activation('relu'))  \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))  \n",
    "    model.add(Dropout(0.25))  \n",
    "      \n",
    "    model.add(Flatten())  \n",
    "    model.add(Dense(256))  \n",
    "    model.add(Activation('relu'))  \n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(2))  \n",
    "    model.add(Activation('softmax'))  \n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#픽셀값 \n",
    "def get_pixel_values():\n",
    "    file_name = './figures_v2'\n",
    "    pixels = []\n",
    "    for filename in glob.glob(file_name + '\\*.png'):\n",
    "        im = misc.imread(filename)\n",
    "        pixels.append(im)\n",
    "    return pixels\n",
    "    \n",
    "#이미지변환   \n",
    "def convert_image():\n",
    "    file_name = './figures_v2'\n",
    "    for filename in glob.glob(file_name + '\\*.png'):\n",
    "        img = Image.open(filename)\n",
    "        img = img.convert('RGB')\n",
    "        img.save(filename)\n",
    "    \n",
    "#이미지 plot(그림그리기)\n",
    "def plot_data(data):\n",
    "    #t = np.arange(0, 29, 1) \n",
    "    t = np.arange(0, 33, 1)# 파일 전체 range 맞춰 변환\n",
    "    file_name_number = 0\n",
    "    fig = plt.figure(frameon=False, figsize=(width, height))\n",
    "    for group in data:\n",
    "        #count = 30 # 파일 전체 갯수가 다르기 때문에 count 범위 수정\n",
    "        count = 34\n",
    "        while count <= (len(group)-5):\n",
    "            high = []\n",
    "            low = []\n",
    "            for item in group[count-34:count]:\n",
    "                high.append(item[0])\n",
    "                low.append(item[1])\n",
    "            file_name = r'\\fig_' + str(file_name_number)\n",
    "            ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "            ax.set_axis_off()\n",
    "            fig.add_axes(ax)\n",
    "            ax.plot(t, high[0:-1], 'b', t, low[0:-1], 'g')\n",
    "            fig.savefig('./figures_v2' + file_name, dpi=100)\n",
    "            fig.clf()\n",
    "#             file_name_number += 1 # 10칸씩 움직이니까 10으로 수정 \n",
    "#             count += 11\n",
    "            file_name_number += 10 # 10칸씩 움직이니까 10으로 수정 \n",
    "            count += 10 \n",
    "    print('Created %d files!' % file_name_number)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 수익률계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터추출 ---- 여기가 문제 같음 \n",
    "\n",
    "\n",
    "def extract_data():\n",
    "    file_name = 'data_3only.csv' #해당파일 open\n",
    "    infile = open(file_name, 'r')\n",
    "    temp_buffer = []\n",
    "    for line in infile:\n",
    "        temp_buffer.append(line.strip('\\n')) # '\\n'기준으로 temp_buffer에 append \n",
    "    temp_buffer = temp_buffer[8:] #실질적인 data 시작지점인 8부터 append 시작\n",
    "    i = 0\n",
    "    groups = []\n",
    "    temp = []\n",
    "    for item in temp_buffer:\n",
    "        #if i != 390: \n",
    "        if i != 1223: #갯수 확인하고 1223개씩 나누기\n",
    "            temp.append(item)\n",
    "            i += 1 # 1씩 추가하기\n",
    "        else:\n",
    "            groups.append(temp)\n",
    "            temp = []\n",
    "            i = 0\n",
    "    groups.append(temp)\n",
    "    infile.close() #해당파일 close \n",
    "    return groups\n",
    "\n",
    "#데이터분할 \n",
    "def split_data(data):\n",
    "    groups = []\n",
    "    for item in data:\n",
    "        temp_buffer = []\n",
    "        for string in item:\n",
    "            number = string.split(',')  # ',' 기준으로 split \n",
    "            temp_buffer.append(number)  # temp_buffer에 append\n",
    "        groups.append(temp_buffer)\n",
    "    print(len(groups))\n",
    "    return groups\n",
    "\n",
    "\n",
    "#분할된 데이터 모으기\n",
    "def load_sample_data():\n",
    "    original_data = extract_data()\n",
    "    splitted_data = split_data(original_data)\n",
    "    useful_data = extract_useful_data(splitted_data)\n",
    "    return useful_data \n",
    "\n",
    "\n",
    "#필요정보취합\n",
    "def extract_useful_data(data):\n",
    "    groups = []\n",
    "    for group in data:\n",
    "        temp_buffer = []\n",
    "        for item in group:\n",
    "            temp = [item[2], item[3]]  \n",
    "            temp = [float(i) for i in temp]\n",
    "            temp_buffer.append(temp)\n",
    "        groups.append(temp_buffer)\n",
    "    #print(len(groups)\n",
    "    return groups\n",
    "\n",
    "\n",
    "#수익률계산  \n",
    "def find_returns(data): \n",
    "    returns = []\n",
    "    price1 = []\n",
    "    price2 = []\n",
    "    for group in data:\n",
    "        count = 34 # 나눈 window 맞춰 count 수정 at plot data\n",
    "        while count <= (len(group)-5):  #count로 나눠진 각각의 값들 (5개묶음이라 시작갯수 5개 제외)\n",
    "            current_data = group[count-1] #현재데이터\n",
    "            future_data = group[count+4] #미래데이터\n",
    "            p1 = np.mean(current_data) #계산1\n",
    "            p2 = np.mean(future_data) #계산2\n",
    "            price1.append(p1) #각각의 결과값 pricen에 append\n",
    "            price2.append(p2) \n",
    "           \n",
    "            #math.log(p2/p1)에서 예외처리\n",
    "            if p1 <= 0 or p2 <= 0: #S1. 아예 ()안이 값이 말이 안되는 경우 \n",
    "                returns.append(0)\n",
    "                count += 10\n",
    "#             elif math.log(p2/p1)>= 2:\n",
    "#                 #S2. log(p2/p1)이 2보다 커서 값이 의미가 없는 경우                    \n",
    "#                 print(p1)\n",
    "#                 print(p2)\n",
    "#                 print('aaaa')\n",
    "#                 returns.append(0)\n",
    "#                 count += 10\n",
    "            else:    \n",
    "                returns.append(math.log(p2/p1)) #S3. 그외 정상적인경우\n",
    "                count += 10\n",
    "                \n",
    "#     print(returns)\n",
    "#     print(price1)\n",
    "#     print(price2)\n",
    "    return returns\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_sample_data()\n",
      "plot_data(data)\n",
      "Created 3570 files!\n",
      "convert_image()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\.conda\\envs\\ml\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\.conda\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\user\\.conda\\envs\\ml\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\.conda\\envs\\ml\\lib\\site-packages\\ipykernel_launcher.py:32: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(100, 100,..., padding=\"valid\")`\n",
      "C:\\Users\\user\\.conda\\envs\\ml\\lib\\site-packages\\ipykernel_launcher.py:34: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
      "C:\\Users\\user\\.conda\\envs\\ml\\lib\\site-packages\\ipykernel_launcher.py:40: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"valid\")`\n",
      "C:\\Users\\user\\.conda\\envs\\ml\\lib\\site-packages\\ipykernel_launcher.py:42: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3))`\n",
      "C:\\Users\\user\\.conda\\envs\\ml\\lib\\site-packages\\ipykernel_launcher.py:37: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn\n",
      "WARNING:tensorflow:From C:\\Users\\user\\.conda\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 357 samples, validate on 357 samples\n",
      "Epoch 1/1\n",
      "357/357 [==============================] - 16s 45ms/step - loss: 0.1880 - val_loss: 1.1921e-07\n",
      "-0.006418514032651146\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 72x72 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def main(): #실행\n",
    "    print('load_sample_data()')\n",
    "    data= load_sample_data()\n",
    "    print('plot_data(data)')\n",
    "    plot_data(data)\n",
    "    convert_image()\n",
    "    print('convert_image()')\n",
    "    x = np.asarray(get_pixel_values())\n",
    "    y = np.asarray(find_returns(data))\n",
    "    x_train = x[0:len(x)] # train, test set 각각의 학습\n",
    "    y_train = y[0:len(y)]\n",
    "    x_test = x[0:len(x)]\n",
    "    y_test = y[0:len(y)]\n",
    "#     x_train = x[0:4340] \n",
    "#     y_train = y[0:4340]\n",
    "#     x_test = x[0:4340]\n",
    "#     y_test = y[0:4340]\n",
    "\n",
    "#    y_true = y_test\n",
    "#    y_train = np_utils.to_categorical(y_train, 2)\n",
    "#    y_test = np_utils.to_categorical(y_test, 2)\n",
    "\n",
    "    x_train = x_train.astype('float32') #train,test set 타입변경\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255.0\n",
    "    x_test /= 255.0\n",
    "\n",
    "    model = create_model()\n",
    "    model = compile_model(model)\n",
    "\n",
    "    print('cnn')\n",
    "    \n",
    "    # Fit the model\n",
    "    epochs = 1\n",
    "    model.fit(x_train, y_train, validation_data=(x_test, y_test), #모델학습과정\n",
    "              nb_epoch=epochs,\n",
    "              shuffle=True, batch_size=100, verbose=1)\n",
    "#    scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "#    print('Accuracy: %.2f%%' % (scores[1] * 100))\n",
    "    classes = model.predict_classes(x_test, verbose=0)\n",
    "    # classes = list(classes) #\n",
    "    list_classes = list(classes)\n",
    "    #y_test = list(y_test)\n",
    "    list_y_test = list(y_test)\n",
    "    r2 = r_squared(list_y_test, list_classes)\n",
    "    print(r2)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
